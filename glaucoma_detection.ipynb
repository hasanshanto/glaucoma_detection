{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Libraries\n",
        "!pip install -q tensorflow scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "print(\"Environment ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlHz5QEN0_C0",
        "outputId": "1a902840-e608-4e91-bbc8-449eeecac173"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the csv\n",
        "df = pd.read_csv(\"clinical_notes.csv\")\n",
        "# see if data is imported succesfully\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00zbGSnr0_Ob",
        "outputId": "b5641222-74c6-4a8d-8f57-ad3027db2ba4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     age  gender   race     ethnicity language maritalstatus  \\\n",
            "0  56.56  female  black  non-hispanic  english        single   \n",
            "1  53.91  female  white  non-hispanic  english        single   \n",
            "2  46.30  female  white  non-hispanic  english        single   \n",
            "3  66.52    male  white  non-hispanic  english        single   \n",
            "4  82.52  female  black  non-hispanic  english      divorced   \n",
            "\n",
            "                                                note  \\\n",
            "0  ms. PERSON is a 56 yo woman presenting to esta...   \n",
            "1  referred for evaluation of narrow angles ou #p...   \n",
            "2  1. left upper lid ptosis: occurred after botox...   \n",
            "3  right plano +0.50 082 left LOCATION -0.50 83 a...   \n",
            "4  in step. os with nonspecific peripheral defect...   \n",
            "\n",
            "                                        gpt4_summary glaucoma       use  \n",
            "0  The 56 y/o female patient has optic nerve head...      yes  training  \n",
            "1  Patient was referred for narrow angle evaluati...      yes  training  \n",
            "2  Patient experienced ptosis, ear and eye pain, ...       no  training  \n",
            "3  The patient has primary open angle glaucoma - ...      yes  training  \n",
            "4  The patient has nonspecific peripheral defects...      yes  training  \n",
            "(10000, 10)\n",
            "Index(['age', 'gender', 'race', 'ethnicity', 'language', 'maritalstatus',\n",
            "       'note', 'gpt4_summary', 'glaucoma', 'use'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean data with lowercase, pronunciation\n",
        "def clean_text(t):\n",
        "    if pd.isna(t):\n",
        "      return \"\"\n",
        "    t = str(t).lower()\n",
        "    t = re.sub(r'[^a-z0-9\\s]', ' ', t)\n",
        "    return re.sub(r'\\s+', ' ', t).strip()\n",
        "\n",
        "data = df.copy()\n",
        "data[\"clean_text\"] = data[\"note\"].apply(clean_text)\n",
        "data[\"label\"] = data[\"glaucoma\"].map({\"yes\": 1, \"no\": 0})\n",
        "data = data.dropna(subset=[\"label\"])\n",
        "\n",
        "# Race column for Asian, Black, White\n",
        "race_col = \"race\" if \"race\" in data.columns else \"ethnicity\"\n",
        "data[race_col] = data[race_col].astype(str)\n",
        "\n",
        "print(\"Race distribution:\")\n",
        "print(data[race_col].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja14AtqZ0_Ra",
        "outputId": "9b477fba-6a7b-44c7-e5be-853e3286dd51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Race distribution:\n",
            "race\n",
            "white    7690\n",
            "black    1491\n",
            "asian     819\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"clean_text\"].values\n",
        "y = data[\"label\"].astype(int).values\n",
        "race = data[race_col].values\n",
        "\n",
        "# Train, Test split\n",
        "X_train, X_test, y_train, y_test, race_train, race_test = train_test_split(\n",
        "    X, y, race, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "# Train, validation split\n",
        "X_train, X_val, y_train, y_val, race_train, race_val = train_test_split(\n",
        "    X_train, y_train, race_train, test_size=0.20, stratify=y_train, random_state=42\n",
        ")\n",
        "# print summary\n",
        "print(f\"Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5ajYYWR0_UV",
        "outputId": "3cdf8124-8076-434d-89fd-8eaf38cfcbdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train=6400, Val=1600, Test=2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count glaucoma vs non-glaucoma samples\n",
        "glaucoma_counts = data['label'].value_counts().sort_index()\n",
        "\n",
        "num_no_glaucoma = glaucoma_counts.get(0, 0)\n",
        "num_glaucoma     = glaucoma_counts.get(1, 0)\n",
        "\n",
        "print(\"========== Glaucoma Label Distribution ==========\")\n",
        "print(f\"No Glaucoma (0): {num_no_glaucoma}\")\n",
        "print(f\"Glaucoma (1):     {num_glaucoma}\")\n",
        "print(f\"Total Samples:    {num_no_glaucoma + num_glaucoma}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msWtUtTJESyg",
        "outputId": "511fb9fc-e3e9-4dd6-d54c-d2a6291caa47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Glaucoma Label Distribution ==========\n",
            "No Glaucoma (0): 4952\n",
            "Glaucoma (1):     5048\n",
            "Total Samples:    10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORDS = 6000 # vocabulary size\n",
        "MAX_LEN = 250 # max length\n",
        "BATCH = 16 # 250 * 16 = 6000\n",
        "\n",
        "# vectorization\n",
        "text_vec = layers.TextVectorization(\n",
        "    max_tokens=MAX_WORDS,\n",
        "    output_sequence_length=MAX_LEN,\n",
        "    standardize=None\n",
        ")\n",
        "text_vec.adapt(X_train)\n",
        "\n",
        "def vectorize(text, label, race):\n",
        "    text = text_vec(text)\n",
        "    return text, label, race\n"
      ],
      "metadata": {
        "id": "J-g0cPFc0_XJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_training_val_dataset(texts, labels):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((texts, labels))\n",
        "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
        "    return ds.map(lambda t, l: (text_vec(t), l))\n",
        "\n",
        "train_ds = make_training_val_dataset(X_train, y_train)\n",
        "val_ds   = make_training_val_dataset(X_val, y_val)\n",
        "\n",
        "# Create a separate dataset for test predictions, containing only input features\n",
        "test_ds_for_prediction = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_ds_for_prediction = test_ds_for_prediction.batch(BATCH).map(text_vec).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "RCVokrzX0_aI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the LSTM model\n",
        "def build_lstm():\n",
        "    inputs = keras.Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "    x = layers.Embedding(MAX_WORDS, 32)(inputs) # 32 dims\n",
        "    x = layers.SpatialDropout1D(0.3)(x)\n",
        "    x = layers.LSTM(32)(x)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x) # 16 unit dense layer\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(5e-4),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "AOWz5xsK0_cx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the GRU model\n",
        "def build_gru():\n",
        "    inputs = keras.Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "    x = layers.Embedding(MAX_WORDS, 32)(inputs) # 32 dims\n",
        "    x = layers.SpatialDropout1D(0.3)(x)\n",
        "    x = layers.GRU(32)(x)\n",
        "    x = layers.Dense(16, activation=\"relu\")(x) # 16 unit\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(5e-4),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "64fszcaU0_fu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building CNN model\n",
        "def build_cnn():\n",
        "    inputs = keras.Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "    x = layers.Embedding(MAX_WORDS, 32)(inputs) # dims 32\n",
        "    x = layers.Conv1D(64, 5, activation=\"relu\")(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(5e-4),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "NNehu3rE0_io"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=3,\n",
        "                                  mode=\"max\", restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", patience=2,\n",
        "                                      factor=0.5, mode=\"max\"),\n",
        "    keras.callbacks.ModelCheckpoint(\"best_model.h5\",\n",
        "                                    monitor=\"val_auc\", mode=\"max\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "models = {\n",
        "    \"LSTM\": build_lstm(),\n",
        "    \"GRU\": build_gru(),\n",
        "    \"CNN\": build_cnn()\n",
        "}\n",
        "\n",
        "histories = {}\n",
        "# Training\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== Training {name} ===\")\n",
        "    hist = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=20, # training for 20 epochs with early stopping\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    histories[name] = hist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f39e2TLl0_ll",
        "outputId": "0b429266-7abc-4ecc-9046-fb03c8a1410f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training LSTM ===\n",
            "Epoch 1/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5091 - auc: 0.5150 - loss: 0.6927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 91ms/step - accuracy: 0.5091 - auc: 0.5150 - loss: 0.6927 - val_accuracy: 0.5050 - val_auc: 0.5392 - val_loss: 0.6921 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5111 - auc: 0.5274 - loss: 0.6922"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 98ms/step - accuracy: 0.5111 - auc: 0.5274 - loss: 0.6922 - val_accuracy: 0.5337 - val_auc: 0.5428 - val_loss: 0.6904 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5333 - auc: 0.5319 - loss: 0.6891"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 101ms/step - accuracy: 0.5332 - auc: 0.5319 - loss: 0.6891 - val_accuracy: 0.5431 - val_auc: 0.5496 - val_loss: 0.6884 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5337 - auc: 0.5323 - loss: 0.6853"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 89ms/step - accuracy: 0.5337 - auc: 0.5324 - loss: 0.6853 - val_accuracy: 0.5450 - val_auc: 0.5554 - val_loss: 0.6823 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 82ms/step - accuracy: 0.5503 - auc: 0.5828 - loss: 0.6706 - val_accuracy: 0.5069 - val_auc: 0.5465 - val_loss: 0.6876 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 82ms/step - accuracy: 0.5530 - auc: 0.6032 - loss: 0.6511 - val_accuracy: 0.5462 - val_auc: 0.5542 - val_loss: 0.6848 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5853 - auc: 0.6324 - loss: 0.6353"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.5853 - auc: 0.6324 - loss: 0.6353 - val_accuracy: 0.5600 - val_auc: 0.5806 - val_loss: 0.6812 - learning_rate: 2.5000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 82ms/step - accuracy: 0.5865 - auc: 0.6417 - loss: 0.6278 - val_accuracy: 0.5194 - val_auc: 0.5691 - val_loss: 0.6921 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 79ms/step - accuracy: 0.5830 - auc: 0.6380 - loss: 0.6255 - val_accuracy: 0.5587 - val_auc: 0.5747 - val_loss: 0.6962 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6031 - auc: 0.6732 - loss: 0.6079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.6031 - auc: 0.6732 - loss: 0.6079 - val_accuracy: 0.5631 - val_auc: 0.5892 - val_loss: 0.6995 - learning_rate: 1.2500e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6090 - auc: 0.6600 - loss: 0.6067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.6090 - auc: 0.6600 - loss: 0.6067 - val_accuracy: 0.5713 - val_auc: 0.6030 - val_loss: 0.7087 - learning_rate: 1.2500e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6117 - auc: 0.6824 - loss: 0.5963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 80ms/step - accuracy: 0.6117 - auc: 0.6824 - loss: 0.5963 - val_accuracy: 0.5725 - val_auc: 0.6038 - val_loss: 0.7106 - learning_rate: 1.2500e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6025 - auc: 0.6749 - loss: 0.5963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 87ms/step - accuracy: 0.6026 - auc: 0.6750 - loss: 0.5963 - val_accuracy: 0.5838 - val_auc: 0.6117 - val_loss: 0.6993 - learning_rate: 1.2500e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6066 - auc: 0.6910 - loss: 0.5886"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 96ms/step - accuracy: 0.6066 - auc: 0.6910 - loss: 0.5886 - val_accuracy: 0.6488 - val_auc: 0.6701 - val_loss: 0.6910 - learning_rate: 1.2500e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 95ms/step - accuracy: 0.6284 - auc: 0.7017 - loss: 0.5857 - val_accuracy: 0.6006 - val_auc: 0.6384 - val_loss: 0.6897 - learning_rate: 1.2500e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 92ms/step - accuracy: 0.6378 - auc: 0.7070 - loss: 0.5880 - val_accuracy: 0.5844 - val_auc: 0.6265 - val_loss: 0.7149 - learning_rate: 1.2500e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 94ms/step - accuracy: 0.6638 - auc: 0.7338 - loss: 0.5670 - val_accuracy: 0.6137 - val_auc: 0.6466 - val_loss: 0.7112 - learning_rate: 6.2500e-05\n",
            "\n",
            "=== Training GRU ===\n",
            "Epoch 1/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 131ms/step - accuracy: 0.5276 - auc: 0.5186 - loss: 0.6924 - val_accuracy: 0.5337 - val_auc: 0.5363 - val_loss: 0.6916 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 129ms/step - accuracy: 0.5151 - auc: 0.5138 - loss: 0.6920 - val_accuracy: 0.5344 - val_auc: 0.5356 - val_loss: 0.6896 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 128ms/step - accuracy: 0.5167 - auc: 0.5173 - loss: 0.6889 - val_accuracy: 0.5288 - val_auc: 0.5283 - val_loss: 0.6868 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 127ms/step - accuracy: 0.5425 - auc: 0.5387 - loss: 0.6796 - val_accuracy: 0.5337 - val_auc: 0.5404 - val_loss: 0.6864 - learning_rate: 2.5000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 128ms/step - accuracy: 0.5507 - auc: 0.5608 - loss: 0.6738 - val_accuracy: 0.5337 - val_auc: 0.5451 - val_loss: 0.6885 - learning_rate: 2.5000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 130ms/step - accuracy: 0.5659 - auc: 0.5680 - loss: 0.6652 - val_accuracy: 0.5331 - val_auc: 0.5427 - val_loss: 0.6935 - learning_rate: 2.5000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 153ms/step - accuracy: 0.5705 - auc: 0.5856 - loss: 0.6601 - val_accuracy: 0.5406 - val_auc: 0.5458 - val_loss: 0.7021 - learning_rate: 2.5000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 126ms/step - accuracy: 0.5689 - auc: 0.5926 - loss: 0.6533 - val_accuracy: 0.5344 - val_auc: 0.5354 - val_loss: 0.7098 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 112ms/step - accuracy: 0.5724 - auc: 0.5856 - loss: 0.6505 - val_accuracy: 0.5306 - val_auc: 0.5306 - val_loss: 0.7182 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 112ms/step - accuracy: 0.5543 - auc: 0.6009 - loss: 0.6467 - val_accuracy: 0.5300 - val_auc: 0.5276 - val_loss: 0.7187 - learning_rate: 1.2500e-04\n",
            "\n",
            "=== Training CNN ===\n",
            "Epoch 1/20\n",
            "\u001b[1m397/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5712 - auc: 0.5873 - loss: 0.6790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.5717 - auc: 0.5883 - loss: 0.6787 - val_accuracy: 0.7256 - val_auc: 0.8131 - val_loss: 0.5328 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m397/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7546 - auc: 0.8280 - loss: 0.5063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7547 - auc: 0.8282 - loss: 0.5061 - val_accuracy: 0.7769 - val_auc: 0.8625 - val_loss: 0.4525 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m397/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8161 - auc: 0.8989 - loss: 0.4039"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8162 - auc: 0.8990 - loss: 0.4037 - val_accuracy: 0.7800 - val_auc: 0.8734 - val_loss: 0.4438 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m397/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8619 - auc: 0.9360 - loss: 0.3288"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8621 - auc: 0.9361 - loss: 0.3285 - val_accuracy: 0.7862 - val_auc: 0.8753 - val_loss: 0.4502 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9023 - auc: 0.9633 - loss: 0.2544 - val_accuracy: 0.7837 - val_auc: 0.8733 - val_loss: 0.4855 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9346 - auc: 0.9797 - loss: 0.1909 - val_accuracy: 0.7856 - val_auc: 0.8718 - val_loss: 0.5190 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9608 - auc: 0.9896 - loss: 0.1361 - val_accuracy: 0.7862 - val_auc: 0.8712 - val_loss: 0.5409 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_GROUPS = [\"asian\", \"black\", \"white\"]\n",
        "\n",
        "# fairness report evaluation\n",
        "def fairness_report(model, test_texts, test_labels, test_races, test_ds_for_prediction):\n",
        "    preds = model.predict(test_ds_for_prediction).flatten()\n",
        "    binary = (preds >= 0.5).astype(int)\n",
        "\n",
        "    # Overall\n",
        "    auc = roc_auc_score(test_labels, preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(test_labels, binary).ravel()\n",
        "    sens = tp/(tp+fn)\n",
        "    spec = tn/(tn+fp)\n",
        "\n",
        "    print(f\"\\nOverall AUC={auc:.4f}, Sens={sens:.4f}, Spec={spec:.4f}\")\n",
        "\n",
        "    # Per group\n",
        "    results = {\"Overall\": {\"auc\": auc, \"sens\": sens, \"spec\": spec}}\n",
        "\n",
        "    for grp in TARGET_GROUPS:\n",
        "        mask = (test_races == grp)\n",
        "        if mask.sum() < 5:\n",
        "            print(f\"{grp}: too few samples\")\n",
        "            continue\n",
        "\n",
        "        auc_g = roc_auc_score(test_labels[mask], preds[mask])\n",
        "        tn, fp, fn, tp = confusion_matrix(test_labels[mask],\n",
        "                                         binary[mask]).ravel()\n",
        "        sens_g = tp/(tp+fn)\n",
        "        spec_g = tn/(tn+fp)\n",
        "\n",
        "        print(f\"{grp} \\u2014 n={mask.sum()} \\u2014 AUC={auc_g:.4f}, Sens={sens_g:.4f}, Spec={spec_g:.4f}\")\n",
        "        results[grp] = {\"auc\": auc_g, \"sens\": sens_g, \"spec\": spec_g}\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0yR0F6Cmo-Xa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance of the 3 models\n",
        "lstm_results = fairness_report(models[\"LSTM\"], X_test, y_test, race_test, test_ds_for_prediction)\n",
        "gru_results  = fairness_report(models[\"GRU\"], X_test, y_test, race_test, test_ds_for_prediction)\n",
        "cnn_results  = fairness_report(models[\"CNN\"], X_test, y_test, race_test, test_ds_for_prediction)"
      ],
      "metadata": {
        "id": "-Mt1J1ok0_rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2e658b-8407-47a0-ba93-7746b860006b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step\n",
            "\n",
            "Overall AUC=0.7247, Sens=0.4109, Spec=0.8818\n",
            "asian — n=157 — AUC=0.7546, Sens=0.3735, Spec=0.8919\n",
            "black — n=301 — AUC=0.7316, Sens=0.4241, Spec=0.8909\n",
            "white — n=1542 — AUC=0.7198, Sens=0.4117, Spec=0.8797\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step\n",
            "\n",
            "Overall AUC=0.5605, Sens=0.1317, Spec=0.9202\n",
            "asian — n=157 — AUC=0.5314, Sens=0.0964, Spec=0.8919\n",
            "black — n=301 — AUC=0.5735, Sens=0.1257, Spec=0.8818\n",
            "white — n=1542 — AUC=0.5611, Sens=0.1372, Spec=0.9280\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "Overall AUC=0.8777, Sens=0.8663, Spec=0.6990\n",
            "asian — n=157 — AUC=0.8881, Sens=0.8675, Spec=0.7703\n",
            "black — n=301 — AUC=0.8840, Sens=0.8534, Spec=0.6818\n",
            "white — n=1542 — AUC=0.8767, Sens=0.8696, Spec=0.6948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========== FINAL SUMMARY ==========\")\n",
        "\n",
        "for name, res in [(\"LSTM\", lstm_results),\n",
        "                  (\"GRU\", gru_results),\n",
        "                  (\"CNN\", cnn_results)]:\n",
        "    print(f\"\\n{name} Overall AUC = {res['Overall']['auc']:.4f}\")\n",
        "\n",
        "    asian_auc = res.get(\"asian\", {}).get(\"auc\", None)\n",
        "    black_auc = res.get(\"black\", {}).get(\"auc\", None)\n",
        "    white_auc = res.get(\"white\", {}).get(\"auc\", None)\n",
        "\n",
        "    print(f\"{name} Asian AUC: {asian_auc:.4f}\")\n",
        "    print(f\"{name} Black AUC: {black_auc:.4f}\")\n",
        "    print(f\"{name} White AUC: {white_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "xzg898bR0_uW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b563bf94-c11c-4837-d117-96307d384bcb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== FINAL SUMMARY ==========\n",
            "\n",
            "LSTM Overall AUC = 0.7247\n",
            "LSTM Asian AUC: 0.7546\n",
            "LSTM Black AUC: 0.7316\n",
            "LSTM White AUC: 0.7198\n",
            "\n",
            "GRU Overall AUC = 0.5605\n",
            "GRU Asian AUC: 0.5314\n",
            "GRU Black AUC: 0.5735\n",
            "GRU White AUC: 0.5611\n",
            "\n",
            "CNN Overall AUC = 0.8777\n",
            "CNN Asian AUC: 0.8881\n",
            "CNN Black AUC: 0.8840\n",
            "CNN White AUC: 0.8767\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}